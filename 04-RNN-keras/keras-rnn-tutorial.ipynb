{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.datasets import imdb\n",
    "from keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 25s 1us/step\n",
      "train: 25000 , test: 25000\n",
      "label: [0 0 0 0 1]\n",
      "features: [[   10    10    17     6    22  1985   255    11   631    62    28    77\n",
      "    128    48     2   109    66    16     6   668  1985    19    41   861\n",
      "      2     6    87   227     7  3588    21    17   230    17  3469  2391\n",
      "      5   541  1554   140    14    31     9   254     8  1559 16128     2\n",
      "      9   345  2516    42     2  5758   469     4    22    63   944     6\n",
      "   1257  1166     7  2172   599  6203     2     2    17     2     5  8548\n",
      "   2234  5252    17     2    26    52   696  1850]\n",
      " [  820   910  1030     8  5817   183    56    11  2716     7    68 12478\n",
      "   4697    10    10   910    70  4146     4   118   927     4   118  1180\n",
      "      5   907    21   131    36  5817   183    56    14    20     9   595\n",
      "      4   619   155     9    15    13  1781   910    11    68  7671   127\n",
      "     24    60   124    54     6    20     9    52    42    78    10    10\n",
      "     12     9    64   688     8     4   676     7     4   156    15    13\n",
      "     70    60   202    12     6   342     7   158]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     1    14    31     9     6   117   128    74     4    86    31\n",
      "     12   131  4066    23     6   176     7    94   486    63   691   941\n",
      "    660    15     4   154  1648   102    71    24   821    15  2899  1523\n",
      "    103    38   111  8276     4   539    71    53   221    11    14    31\n",
      "     10    10    50     9     6  3539  1166     7   964  2742    46   486\n",
      "   2363    31   251   147   212    80   216   145]\n",
      " [    9    11     4   945    18   988     5    31    85    10    10     4\n",
      "    431   489     5   481   489    26   338    11    14    22     4    65\n",
      "      9  9141    19   621  1396    21     4   690    26    78     5  5839\n",
      "   5383    47     6   394   544  3052   218    15    52   345   240  2211\n",
      "    195    21    64    66   266     8   113    54   395     4  9397    42\n",
      "      2    50     9     6    55  2227   109    37   299     6  7212  2658\n",
      "  11206     2     5     4    22     9    43   753]\n",
      " [    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     1   219    14    20    33     4     2     2    25\n",
      "    203   888    49  4145     7     4  3011    40  6008     6 11129   812\n",
      "     18   141     6  2728     5   527   875    21    14    20   252  1936\n",
      "     25    11     4  5565   262     4   236   139    71   220  1350     8\n",
      "    106   440    12   214     4  5005    12  1015]]\n"
     ]
    }
   ],
   "source": [
    "class Data:\n",
    "    def __init__(self, max_features=20000, maxlen=80):\n",
    "        (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "        # 입력 문장의 최대 길이(80)보다 클 경우 잘라내고, 작을 경우 앞에 padding(0)을 추가\n",
    "        x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "        x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "        self.x_train, self.y_train = x_train, y_train\n",
    "        self.x_test, self.y_test = x_test, y_test\n",
    "\n",
    "\n",
    "# data lookup\n",
    "data = Data()\n",
    "print('train:', len(data.y_train), ', test:', len(data.y_test))\n",
    "print('label:', data.y_train[20000:20005])\n",
    "print('features:', data.x_train[20000:20005])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단어가 2000개면 숫자가 numeric X data의 range가 0~2000 이 되는 encoding 개념."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 80, 128)           2560000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,691,713\n",
      "Trainable params: 2,691,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 80, 128)           2560000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               263168    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,823,425\n",
      "Trainable params: 2,823,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class RNN_LSTM1(models.Model):\n",
    "    def __init__(self, max_features, maxlen, bidirectional):\n",
    "        x = layers.Input((maxlen,))    # 입력. 차원: [배치, maxlen(80), 1]\n",
    "        e = layers.Embedding(max_features, 128)(x)    # 임베딩. 차원: [배치, maxlen(80), 임베딩 차원(128)]\n",
    "        if bidirectional:\n",
    "            # 양방향일 경우 layers.Bidirectional 모듈로 한번 감싸줍니다.\n",
    "            # 차원: [배치, maxlen(80), 128 * 2]\n",
    "            h = layers.Bidirectional(layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2))(e)\n",
    "        else:\n",
    "            # 차원: [배치, maxlen(80), 128]\n",
    "            h = layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2)(e)\n",
    "        y = layers.Dense(1, activation='sigmoid')(h)    # 출력. 차원: [배치, 1]\n",
    "        super().__init__(x, y)\n",
    "\n",
    "        # try using different optimizers and different optimizer configs\n",
    "        self.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 모델 내부 구조를 살펴봅니다.\n",
    "model1 = RNN_LSTM1(max_features=20000, maxlen=80, bidirectional=False)\n",
    "model1.summary()\n",
    "\n",
    "# LSTM을 양방향(bidirectional)으로 했을 때\n",
    "model2 = RNN_LSTM1(max_features=20000, maxlen=80, bidirectional=True)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
